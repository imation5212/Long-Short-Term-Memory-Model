# Loading date wrangling package
from datetime import datetime
# Data wrangling
import pandas as pd
import numpy as np
import matplotlib as mpl
import tensorflow as tf

# Deep learning: 
from keras.preprocessing.sequence import TimeseriesGenerator
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,mean_squared_error
from keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense,Dropout,LeakyReLU
#from tensorflow.keras import optimizers

mpl.rcParams['figure.figsize']=(10,8)
mpl.rcParams['axes.grid']=False

# Reading the input data
#df = pd.read_excel('Load_Set.xlsx')
df = pd.read_excel('Thesis_data.xlsx')
df_energy_load=df.copy()
# Formating to datetime
#df_energy_load.reset_index(inplace=False)
df_energy_load['DateTime'] = pd.to_datetime(df_energy_load['DateTime'],format='%Y-%m-%dT%H:%M:%SZ')
df_energy_load = df_energy_load.set_index('DateTime')
df_energy_load = df_energy_load.asfreq('30min')
# Sorting the values
df_energy_load.sort_values('DateTime', inplace=True)

def create_features(Kenya):
    """
    create time series features based on time series index.
    """
    Kenya["hour"] = Kenya.index.hour
    Kenya["dayofweek"] = Kenya.index.day_of_week
    Kenya["month"] = Kenya.index.month
    return Kenya
df_energy_load = create_features(df_energy_load)
# Aggregating in 1Hour intervals
# ==============================================================================
# The Date column is eliminated so that it does not generate an error when aggregating.
# The Holiday column does not generate an error since it is Boolean and is treated as 0-1.
#df_energy_load = df_energy_load.resample(rule='H', closed='left', label ='right').max()
df_energy_load = df_energy_load.resample(rule='H').max()
df_energy_load.index.freq
print(df_energy_load)
# Verify that a temporary index is complete
# ==============================================================================
print((df_energy_load.index == pd.date_range(start=df_energy_load.index.min(),
                              end=df_energy_load.index.max(),
                              freq=df_energy_load.index.freq)).all())
                              
scaler=MinMaxScaler()
data_scaled=scaler.fit_transform(df_energy_load)
data_scaled.shape[1]
data_scaled

class RNN_TS_model():
    """
    A class to create a deep time series model
    """
    def __init__(
        self,
        #data:pd.DataFrame,
        data,
        #features_var:list, 
        #target_var: float,
        lag: int,
        LSTM_layer_depth: int, 
        epochs=10, 
        batch_size=256,
        train_test_split=0,
        verbose=1
    ):

        self.data = data
        #self.X_var = features_var 
        #self.Y_var = target_var 
        self.lag = lag 
        self.LSTM_layer_depth = LSTM_layer_depth
        self.batch_size = batch_size
        self.epochs = epochs
        self.train_test_split = train_test_split
        self.verbose=verbose

    @staticmethod
    def create_multivariate_X_Y(ts_features: list,ts_target: list, lag:int) -> list:
        """
        A method to create X and Y matrix from a time series list for the training of 
        deep learning models

        Window_length is the lag argument
        The stride and sampling rate are fixed at 1
        """
        X_data, Y_data = [], []
        

        if len(ts_features) - lag <= 0:        
            X_data.append(ts_features)
        else:
            for i in range(len(ts_features) - lag):            
                X_data.append(ts_features[i:(i + lag)])
            for i in range(len(ts_target) - lag):            
                Y_data.append(ts_target[i + lag])

        X, Y = np.array(X_data), np.array(Y_data)
        print("X.shape[0]: ",X.shape[0])
        print("X.shape[1]: ",X.shape[1])
        print("X.shape[2]: ",X.shape[2])
        
        # Reshaping the X array to an LSTM input shape 
        X = np.reshape(X, (X.shape[0],X.shape[1],X.shape[2], 1))

        return X, Y         

    def create_multivariate_data_for_NN(
        self,
        use_last_n=None
        ):
        """
        A method to create data for the neural network model
        """
        # Extracting the features to be incorporated in the train data set
        #x=self.data[self.X_var].to_numpy().tolist()
        x=self.data
        """
        x=self.data[['MW','Holiday','hour','dayofweek','month']].to_numpy().tolist()
        
        """

        # Extracting the main variable we want to model/forecast
        """
        y=self.data['MW'].tolist()
        """
        #y = self.data[self.Y_var].tolist()
        y = self.data[:,0]

        # Subseting the time series if needed
        if use_last_n is not None:
            y = y[-use_last_n:]

        # The X matrix will hold the lags of Y 
        X, Y = self.create_multivariate_X_Y(x,y, self.lag)

        # Creating training and test sets 
        X_train = X
        X_test = []

        Y_train = Y
        Y_test = []

        if self.train_test_split > 0:
            index = round(len(X) * self.train_test_split)
            X_train = X[:(len(X) - index)]
            X_test = X[-index:]     
            
            Y_train = Y[:(len(X) - index)]
            Y_test = Y[-index:]

        return X_train, X_test, Y_train, Y_test
    def LSTM_multivariate_model1(self):
            """
            A method to fit the LSTM model 
            """
            # Getting the data
            X_train, X_test, Y_train, Y_test = self.create_multivariate_data_for_NN()        

            # Defining the model
            model = Sequential()
            model.add(LSTM(self.LSTM_layer_depth, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))
            model.add(Dense(1))
            model.compile(optimizer='adam', loss='mse')



            # Defining the model parameter dict 
            keras_dict = {
                'x': X_train,
                'y': Y_train,
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'validation_data':X_test,
                'shuffle': False,
                'verbose':self.verbose
            }

            if self.train_test_split > 0:
                keras_dict.update({
                    'validation_data': (X_test, Y_test)
                })

            # Fitting the model 
            model.fit(
                **keras_dict
            )

            # Saving the model to the class 
            self.model = model

            return model
    def LSTM_multivariate_model2(self):
            # Getting the data
            X_train, X_test, Y_train, Y_test = self.create_multivariate_data_for_NN()

            # Defining the model2
            model2=Sequential()
            model2.add(LSTM(self.LSTM_layer_depth, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True))
            model2.add(LeakyReLU(alpha=0.5))
            model2.add(LSTM(self.LSTM_layer_depth,return_sequences=True))
            model2.add(LeakyReLU(alpha=0.5))
            model2.add(Dropout(0.3))
            model2.add(LSTM(64,return_sequences=False))
            model2.add(Dropout(0.3))
            model2.add(Dense(1))
            
            model2.compile(loss=tf.losses.MeanSquaredError(),
            optimizer=tf.optimizers.Adam(),metrics=[tf.metrics.MeanAbsoluteError()])

            early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',
            patience=2,mode='min')

            # Defining the model2 parameter dict 
            keras_dict2 = {
                'x': X_train,
                'y': Y_train,
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'validation_data':X_test,
                'shuffle': False,
                'verbose':self.verbose,
                'callbacks':[early_stopping]
            }

            if self.train_test_split > 0:
                keras_dict2.update({
                    'validation_data': (X_test, Y_test)
                })

            # Fitting the model 
            model2.fit(
                **keras_dict2
            )
            # Saving the model to the class 
            self.model2 = model2

            return model2
            
    def predict(self) -> list:
          """
          A method to predict using the test data used in creating the class
          """
          #yhat = []

          if(self.train_test_split > 0):
          
              # Getting the last n time series 
              _, X_test, _, yTest = self.create_multivariate_data_for_NN()        

              # Making the prediction list 
              yhat = self.model.predict(X_test)

          return X_test,yTest,yhat

    def predict_n_ahead(self, n_ahead: int):
        """
        A method to predict n time steps ahead
        """    
        X, _, _, _ = self.create_multivariate_data_for_NN(use_last_n=self.lag)        

        # Making the prediction list 
        yhat = []

        for _ in range(n_ahead):
            # Making the prediction
            fc = self.model.predict(X)
            yhat.append(fc)

            # Creating a new input matrix for forecasting
            X = np.append(X, fc)

            # Ommiting the first variable
            X = np.delete(X, 0)

            # Reshaping for the next iteration
            X = np.reshape(X, (1, len(X), 1))

        return yhat
    deep_learner=RNN_TS_model(
    data=data_scaled,
    #features_var=['MW','hour','dayofweek','month'],
    #target_var="MW",
    lag=24,
    LSTM_layer_depth=128,
    epochs=70, 
    batch_size=32,
    train_test_split=0.2,
    verbose=1)        
model1=deep_learner.LSTM_multivariate_model1()
model2=deep_learner.LSTM_multivariate_model2()
xtest,ytest,yhat=deep_learner.predict()
xtest,ytest,yhat=deep_learner.predict()
rev_transformation=scaler.inverse_transform(df_pred)
rev_transformation
# Constructing the insample forecast dataframe
insample_forecast=df_energy_load.tail(len(yhat)).copy()

insample_forecast.count()
insample_forecast['Forecast']=rev_transformation[:,0]
insample_forecast.reset_index(inplace=True)
insample_forecast
insample_forecast.set_index('DateTime')[['MW','Forecast']].plot()
mse=mean_squared_error(insample_forecast["MW"],insample_forecast["Forecast"])
print("MSE: ", mse)
rmse=np.sqrt(mse)
print("RMSE: ", rmse)
r2=r2_score(ytest,yhat)
print("R2: ",r2)
